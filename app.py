
import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import traceback
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
import feedparser
import urllib.parse
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import HistGradientBoostingClassifier

# è¨­å®šé é¢è³‡è¨Š
st.set_page_config(page_title="AI é‡åŒ–äº¤æ˜“ç­–ç•¥å¯¦å®¤ (Portfolio Edition)", layout="wide", page_icon="ğŸ“ˆ")

st.title("ğŸ¤– AI é‡åŒ–äº¤æ˜“ç­–ç•¥å¯¦é©—å®¤ (Portfolio Edition)")
st.markdown("### 2-Stage Gate: VIX Regime + Dynamic Quantile Model")

# --------------------------
# Sidebar: User Inputs
# --------------------------
st.sidebar.header("âš™ï¸ åƒæ•¸è¨­å®š")

# ä¿®æ”¹ï¼šæ”¹æˆ Text Area æ”¯æ´å¤šæª”è‚¡ç¥¨
# æ–°å¢ï¼šExcel ä¸Šå‚³åŠŸèƒ½
uploaded_file = st.sidebar.file_uploader("ğŸ“ ä¸Šå‚³æŒæœ‰æ¸…å–® (Excel)", type=["xlsx", "xls"])

# Initialize session state for tickers
if 'tickers_text' not in st.session_state:
    st.session_state['tickers_text'] = "2330.TW\n2317.TW\n2454.TW"
if 'last_uploaded_file' not in st.session_state:
    st.session_state['last_uploaded_file'] = None

# Logic: Process file ONLY if it is new
if uploaded_file is not None and uploaded_file != st.session_state['last_uploaded_file']:
    try:
        df_upload = pd.read_excel(uploaded_file)
        # æ™ºæ…§åµæ¸¬æ¬„ä½
        possible_cols = ['è‚¡ç¥¨ä»£è™Ÿ', 'Ticker', 'Symbol', 'Code', 'Stock', 'è‚¡è™Ÿ', 'ä»£è™Ÿ']
        target_col = None
        cols_clean = [str(c).strip() for c in df_upload.columns]
        
        for p in possible_cols:
            matches = [i for i, c in enumerate(cols_clean) if c.lower() == p.lower()]
            if matches:
                target_col = df_upload.columns[matches[0]]
                break
        
        raw_list = []
        if target_col:
            st.sidebar.success(f"è®€å–æˆåŠŸï¼æ¬„ä½ï¼š{target_col}")
            raw_list = df_upload[target_col].dropna().tolist()
        else:
            st.sidebar.warning("æœªåµæ¸¬åˆ°ä»£è™Ÿæ¬„ä½ï¼Œé è¨­ä½¿ç”¨ç¬¬ä¸€æ¬„")
            raw_list = df_upload.iloc[:, 0].astype(str).tolist()
            
        # Clean and Format
        cleaned = []
        for item in raw_list:
            s = str(item).strip()
            if s.isdigit() and len(s) < 4: s = s.zfill(4)
            if not s.upper().endswith('.TW') and not s.upper().endswith('.TWO'): s += '.TW'
            cleaned.append(s)
            
        # Update Session State
        unique_tickers = list(dict.fromkeys(cleaned))
        st.session_state['tickers_text'] = "\n".join(unique_tickers)
        st.session_state['last_uploaded_file'] = uploaded_file
        st.sidebar.info(f"å·²åŒ¯å…¥ {len(unique_tickers)} æª”è‚¡ç¥¨è‡³ä¸‹æ–¹åˆ—è¡¨ä¸­ã€‚")
        
    except Exception as e:
        st.sidebar.error(f"è§£æå¤±æ•—: {e}")

input_tickers = st.sidebar.text_area(
    "è‚¡ç¥¨ä»£è™Ÿæ¸…å–® (å¯æ‰‹å‹•ä¿®æ”¹)", 
    value=st.session_state['tickers_text'],
    height=150,
    key='tickers_input_widget', # Unique key
    help="ä¸Šå‚³ Excel å¾Œæœƒè‡ªå‹•å¡«å…¥æ­¤è™•ï¼Œæ‚¨ä¹Ÿå¯ä»¥æ‰‹å‹•ç·¨è¼¯ã€‚"
)

# Update session state if user edits text area manually
if input_tickers != st.session_state['tickers_text']:
     st.session_state['tickers_text'] = input_tickers



if st.sidebar.button("ğŸ§¹ æ¸…é™¤å¿«å– (Clear Cache)"):
    st.cache_data.clear()
    st.sidebar.success("å¿«å–å·²æ¸…é™¤ï¼è«‹é‡æ–°åŸ·è¡Œåˆ†æã€‚")

st.sidebar.caption(f"yfinance version: {yf.__version__}")

YEARS_BACK = st.sidebar.slider("å›æ¸¬å¹´æ•¸", min_value=1, max_value=5, value=3)

# é€²éšåƒæ•¸å€
with st.sidebar.expander("é€²éšåƒæ•¸ (Advanced)", expanded=False):
    COST = st.number_input("å–®é‚Šäº¤æ˜“æˆæœ¬ (Cost)", value=0.001, step=0.0005, format="%.4f")
    HOLD_DAYS = st.number_input("æŒæœ‰å¤©æ•¸ (Hold Days)", value=3, min_value=1)
    
run_btn = st.sidebar.button("ğŸš€ é–‹å§‹æ‰¹æ¬¡åˆ†æ (Batch Run)", type="primary")

# --------------------------
# Core Logic Functions
# --------------------------

@st.cache_data(ttl=3600)
def download_macro_data(years):
    """åªä¸‹è¼‰ä¸€æ¬¡å®è§€æ•¸æ“šä¸¦å¿«å–"""
    today = datetime.now()
    start_date = (today - timedelta(days=365*years)).strftime("%Y-%m-%d")
    end_date = today.strftime("%Y-%m-%d")
    
    # Critical Global Tech Trend Indicators: NVDA (AI), MU (Memory)
    tickers_macro = ['^VIX', 'DX-Y.NYB', '^TNX', '^SOX', '^GSPC', '^TWII', 'NVDA', 'MU']
    df_macro = yf.download(tickers_macro, start=start_date, end=end_date, auto_adjust=True)
    
    # Handle yfinance recent changes or single-ticker return result
    if isinstance(df_macro.columns, pd.MultiIndex):
        try:
            df_macro_close = df_macro['Close'].copy()
        except KeyError:
             df_macro_close = df_macro.copy()
    else:
        if 'Close' in df_macro.columns:
             df_macro_close = df_macro['Close'].copy()
        else:
             df_macro_close = df_macro.copy()
             
    if isinstance(df_macro_close, pd.Series):
        df_macro_close = df_macro_close.to_frame()
        
    df_macro_close.index = pd.to_datetime(df_macro_close.index).tz_localize(None)
    
    # Rename mapping
    rename_map = {
        '^VIX': 'VIX', 
        'DX-Y.NYB': 'DXY', 
        '^TNX': 'US_10Y',
        '^SOX': 'SOX',
        '^GSPC': 'SP500',
        '^TWII': 'TWII',
        'NVDA': 'NVDA',
        'MU': 'MU'
    }
    df_macro_close.rename(columns=rename_map, inplace=True)
    
    # Ensure all expected columns exist (fill missing with NaN to avoid KeyError)
    for target_col in rename_map.values():
        if target_col not in df_macro_close.columns:
            df_macro_close[target_col] = np.nan
            
    return df_macro_close, start_date, end_date

@st.cache_data(ttl=600)  # News cache shorter (10 min)
def get_stock_news(ticker):
    """å–å¾—å€‹è‚¡ç›¸é—œ Google News"""
    try:
        # æ¸…ç†ä»£è™Ÿ (e.g. 2330.TW -> 2330) æˆ–æ˜¯ç›´æ¥ç”¨ "2330.TW stock"
        # æœå°‹é—œéµå­—ï¼š"{Ticker} stock"
        query = f"{ticker} stock"
        encoded_query = urllib.parse.quote(query)
        rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
        
        feed = feedparser.parse(rss_url)
        
        news_items = []
        for entry in feed.entries[:5]:  # Top 5 news
            news_items.append({
                "title": entry.title,
                "link": entry.link,
                "published": entry.published or ""
            })
            
        return news_items
    except Exception as e:
        return []

@st.cache_data(ttl=3600)
def download_stock_data(ticker, start_date, end_date):
    """ä¸‹è¼‰å€‹åˆ¥è‚¡ç¥¨æ•¸æ“š"""
    df = yf.download(ticker, start=start_date, end=end_date, auto_adjust=True)
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.get_level_values(0)
    
    if df.empty:
        return None
        
    df = df[['Close', 'Volume']].copy()
    df.index = pd.to_datetime(df.index).tz_localize(None)
    return df

def feature_engineering(df_stock, df_macro):
    # Merge
    df = df_stock.join(df_macro, how='left')
    df.ffill(inplace=True)
    df.dropna(inplace=True)
    
    # Tech
    df['SMA_5'] = df['Close'].rolling(5).mean()
    
    # RSI
    delta = df['Close'].diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    rs = gain.rolling(14).mean() / loss.rolling(14).mean()
    df['RSI_14'] = 100 - (100 / (1 + rs))
    
    df['Mom_3d'] = df['Close'].pct_change(3)

    df['Mom_3d'] = df['Close'].pct_change(3)

    # Macro Features (Safe Compute)
    if 'VIX' in df.columns:
        df['VIX_Chg'] = df['VIX'].pct_change()
        df['VIX_Chg_3d'] = df['VIX'].pct_change(3)
        df['VIX_med60'] = df['VIX'].rolling(60).median().shift(1)
    
    if 'DXY' in df.columns: df['DXY_Chg'] = df['DXY'].pct_change()
    if 'US_10Y' in df.columns: df['US10Y_Chg'] = df['US_10Y'].pct_change()
    if 'SOX' in df.columns: df['SOX_Chg'] = df['SOX'].pct_change()
    if 'SP500' in df.columns: df['SP500_Chg'] = df['SP500'].pct_change()
    if 'TWII' in df.columns: df['TWII_Chg'] = df['TWII'].pct_change()
    
    # AI/Memory Trend Features
    if 'NVDA' in df.columns: df['NVDA_Chg'] = df['NVDA'].pct_change()
    if 'MU' in df.columns: df['MU_Chg'] = df['MU'].pct_change()

    # Target Logic
    # Backtest uses this (Return tomorrow)
    df['Next_Return'] = df['Close'].shift(-1) / df['Close'] - 1
    # Training uses this (Return 3 days later)
    df['Return_3d'] = df['Close'].shift(-3) / df['Close'] - 1
    df['Target'] = (df['Return_3d'] > 0.003).astype(int)

    # Base Features
    base_features = ['SMA_5', 'RSI_14', 'Mom_3d', 'Volume']
    macro_candidates = [
        'VIX', 'VIX_Chg', 'VIX_Chg_3d', 
        'DXY', 'DXY_Chg', 
        'US_10Y', 'US10Y_Chg',
        'SOX_Chg', 'SP500_Chg', 'TWII_Chg',
        'NVDA_Chg', 'MU_Chg' # Added new features
    ]
    
    # Filter available features
    features = base_features + [c for c in macro_candidates if c in df.columns]
    
    for c in features:
        df[c] = df[c].shift(1)
        
    df.dropna(inplace=True)
    
    return df, features

def run_analysis_for_ticker(ticker, df_macro, start_date, end_date):
    """åŸ·è¡Œå–®ä¸€è‚¡ç¥¨çš„å®Œæ•´åˆ†ææµç¨‹"""
    try:
        # 1. Download Stock
        df_stock = download_stock_data(ticker, start_date, end_date)
        if df_stock is None:
            return {"status": "error", "msg": f"ç„¡è³‡æ–™ (No Data) - {ticker}"}
        if len(df_stock) < 60:
            return {"status": "error", "msg": f"è³‡æ–™ä¸è¶³ ({len(df_stock)}ç­†) - {ticker}"}
            
        # 2. FE
        df_feat, features = feature_engineering(df_stock, df_macro)
        if len(df_feat) < 50:
            return {"status": "error", "msg": "Not enough data after FE"}

        # 3. Model & Backtest (Simplified for batch speed)
        # é€™è£¡åªè·‘ä¸€å€‹æœ€ä½³åƒæ•¸æƒæçš„ç°¡åŒ–ç‰ˆï¼Œæˆ–è€…å›ºå®šç”¨ä¸€å€‹è¼ƒå¥½çš„ Quantile (e.g. 0.6) ä»¥ç¯€çœæ™‚é–“ï¼Ÿ
        # ç‚ºäº†æ•ˆèƒ½ï¼Œæˆ‘å€‘é€™è£¡å›ºå®šæƒæå¹¾å€‹é—œéµ Quantileï¼Œå–æœ€å¥½çš„ã€‚
        
        X = df_feat[features]
        y = df_feat['Target']
        
        # Train final model on FULL data first to get latest signal
        final_model = HistGradientBoostingClassifier(random_state=42)
        final_model.fit(X, y)
        
        # Latest Signal
        last_row = df_feat.iloc[[-1]]
        latest_proba = final_model.predict_proba(last_row[features])[:, 1][0]
        
        # Calculate Threshold (Dynamic 252d)
        # ç‚ºäº† batch é€Ÿåº¦ï¼Œæˆ‘å€‘é è¨­ç”¨ Q=0.6 (ç›¸å°ç©©å¥)
        # å¦‚æœç”¨æˆ¶å¸Œæœ›æ¯å€‹éƒ½æƒæï¼Œå¯ä»¥åœ¨é€™è£¡åŠ å…¥ç°¡å–®çš„ CVã€‚
        # ç‚ºäº†é«”é©—ï¼Œæˆ‘å€‘é€™è£¡åšä¸€å€‹å¿«é€Ÿçš„ TimeSeriesSplit é©—è­‰ç²åˆ©èƒ½åŠ›
        
        tscv = TimeSeriesSplit(n_splits=3) # æ¸›å°‘ split åŠ å¿«é€Ÿåº¦
        model = HistGradientBoostingClassifier(random_state=42)
        
        total_ret = 0
        qs = [0.55, 0.60, 0.65] # æƒæç¯„åœç¸®å°
        best_q = 0.60
        best_equity = -999
        best_curve = None
        
        for q in qs:
            # ç°¡æ˜“å›æ¸¬é‚è¼¯
            # ç•¥éå®Œæ•´çš„é€æ—¥å›æ¸¬ï¼Œæ”¹ç”¨å‘é‡åŒ–ä¼°ç®—ä»¥åŠ é€Ÿ
            # æ³¨æ„ï¼šé€™è£¡ç‚ºäº†é€Ÿåº¦åšé©åº¦ç°¡åŒ–
            preds = []
            truths = []
            
            # é€™è£¡æˆ‘å€‘åªåšæœ€å¾Œä¸€æŠ˜çš„é©—è­‰ä¾†ç•¶ä½œæˆç¸¾å–®ï¼Œé¿å…è·‘å¤ªä¹…
            # Train last 80%, Test last 20%
            split_idx = int(len(X) * 0.8)
            X_tr, X_te = X.iloc[:split_idx], X.iloc[split_idx:]
            y_tr, y_te = y.iloc[:split_idx], y.iloc[split_idx:]
            
            model.fit(X_tr, y_tr)
            
            # Context
            proba_tr = model.predict_proba(X_tr.iloc[-252:])[:, 1] if len(X_tr) > 252 else model.predict_proba(X_tr)[:, 1]
            proba_te = model.predict_proba(X_te)[:, 1]
            
            full_prob = np.concatenate([proba_tr, proba_te])
            thresh_series = pd.Series(full_prob).rolling(252, min_periods=1).quantile(q)
            te_thresh = thresh_series.iloc[-len(proba_te):].values
            
            # Calc Return
            test_df = df_feat.iloc[split_idx:].copy()
            test_df['proba'] = proba_te
            test_df['thresh'] = te_thresh
            
            # Logic
            mask_market = test_df['VIX'] < test_df['VIX_med60']
            mask_model = test_df['proba'] >= test_df['thresh']
            test_df['signal'] = (mask_market & mask_model).astype(int)
            
            # Simple equity (Buy Next Return - Cost)
            # å¿½ç•¥ Hold 3 days ç´°ç¯€ï¼Œç°¡åŒ–ç‚º Daily Impact for Selection
            daily_ret = test_df['signal'] * (test_df['Next_Return'] - COST) 
            final_eq = (1 + daily_ret).cumprod().iloc[-1]
            
            if final_eq > best_equity:
                best_equity = final_eq
                best_q = q
                best_curve = (1 + daily_ret).cumprod()

        # Get Threshold for TODAY using Best Q
        proba_history = final_model.predict_proba(X)[:, 1]
        current_thresh = pd.Series(proba_history).rolling(252).quantile(best_q).iloc[-1]
        
        # Final Decision
        market_ok = True
        if 'VIX' in df_feat.columns and 'VIX_med60' in df_feat.columns:
            latest_vix = df_feat['VIX'].iloc[-1]
            vix_med = df_feat['VIX_med60'].iloc[-1]
            if not pd.isna(latest_vix) and not pd.isna(vix_med):
                market_ok = latest_vix < vix_med
        
        model_ok = latest_proba >= current_thresh
        
        action = "âœ… BUY" if (market_ok and model_ok) else "ğŸ›‘ WAIT"
        
        return {
            "status": "ok",
            "ticker": ticker,
            "close": df_feat['Close'].iloc[-1],
            "proba": latest_proba,
            "thresh": current_thresh,
            "best_q": best_q,
            "market_ok": market_ok,
            "model_ok": model_ok,
            "action": action,
            "equity_test": best_equity, # Last 20% sample performance
            "curve": best_curve,
            "df_feat_tail": df_feat.tail(5) # For detail view
        }
        
    except Exception as e:
        return {"status": "error", "msg": str(e), "traceback": traceback.format_exc()}

# --------------------------
# Main Execution
# --------------------------
if run_btn:
    # 3. ä½¿ç”¨ Text Area çš„å…§å®¹ (ç¾åœ¨ Excel å·²ç¶“å¡«é€²å»äº†)
    raw_tickers = [t.strip() for t in input_tickers.replace(',', '\n').split('\n') if t.strip()]
    
    if not raw_tickers:
        st.error("è«‹è¼¸å…¥è‡³å°‘ä¸€æ”¯è‚¡ç¥¨ä»£è™Ÿ")
        st.stop()
        
    st.write(f"ğŸ“Š æº–å‚™åˆ†æ {len(raw_tickers)} æª”è‚¡ç¥¨...")
    
    # 1. Download Macro (Once)
    st.info("ğŸ“¥ ä¸‹è¼‰å®è§€æ•¸æ“šä¸­ (Macro Data)...")
    try:
        df_macro, start_dt, end_dt = download_macro_data(YEARS_BACK)
    except Exception as e:
        st.error(f"å®è§€æ•¸æ“šä¸‹è¼‰å¤±æ•—: {e}")
        st.stop()
        
    # 2. Loop Tickers
    results = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, t in enumerate(raw_tickers):
        pct = (i) / len(raw_tickers)
        progress_bar.progress(pct)
        status_text.text(f"æ­£åœ¨åˆ†æ {t} ({i+1}/{len(raw_tickers)})...")
        
        res = run_analysis_for_ticker(t, df_macro, start_dt, end_dt)
        if res['status'] == 'ok':
            # Append result
            results.append({
                "Ticker": t,
                "Action": res['action'],
                "Confidence": f"{res['proba']:.1%}",
                "Threshold": f"{res['thresh']:.1%}",
                "Market(VIX)": "Safe" if res['market_ok'] else "Risk",
                "Backtest(Last20%)": f"{res['equity_test']:.2f}x",
                "Close": f"{res['close']:.2f}",
                # Hidden objects for details
                "_raw_res": res
            })
        else:
            # Error row
            error_msg = res['msg']
            # Simplify error for table
            short_err = (error_msg[:30] + '..') if len(error_msg) > 30 else error_msg
            
            results.append({
                "Ticker": t,
                "Action": f"âŒ {short_err}",
                "Confidence": "-",
                "Threshold": "-",
                "Market(VIX)": "-",
                "Backtest(Last20%)": "-",
                "Close": "-",
                "_error": res['msg'],
                "_traceback": res.get('traceback', '')
            })
            
    progress_bar.progress(1.0)
    status_text.text("åˆ†æå®Œæˆï¼")
    
    # 3. Summary Dashboard
    st.markdown("---")
    st.subheader("ğŸ“Š æŠ•è³‡çµ„åˆç¸½é«”æª¢ (Portfolio Summary)")
    
    if results:
        df_res = pd.DataFrame(results)
        # Drop hidden cols for table
        disp_cols = [c for c in df_res.columns if not c.startswith('_')]
        
        # Color styling function
        def highlight_action(val):
            color = 'lightgreen' if 'BUY' in str(val) else 'white'
            if 'âŒ' in str(val) or 'ERROR' in str(val): color = 'lightcoral'
            return f'background-color: {color}'
        
        st.dataframe(df_res[disp_cols].style.applymap(highlight_action, subset=['Action']))
        
        # 4. Detailed View
        st.markdown("### ğŸ” å€‹è‚¡è©³ç´°åˆ†æ (Details)")
        
        for r in results:
            t = r['Ticker']
            with st.expander(f"{t} - {r['Action']}", expanded=False):
                if 'âŒ' in r['Action'] or 'ERROR' in r['Action']:
                    st.error(f"éŒ¯èª¤åŸå› : {r.get('_error', 'Unknown')}")
                    if '_traceback' in r:
                        st.code(r['_traceback'], language='python')
                else:
                    # Tabs for Analysis vs News
                    tab1, tab2 = st.tabs(["ğŸ“Š æ•¸æ“šåˆ†æ", "ğŸ—ï¸ ç›¸é—œæ–°è"])
                    
                    detail = r['_raw_res']
                    
                    with tab1:
                        c1, c2 = st.columns([1, 2])
                        
                        with c1:
                            st.metric("æœ€æ–°æ”¶ç›¤", detail['close'])
                            st.metric("æ¨¡å‹ä¿¡å¿ƒ", f"{detail['proba']:.1%}", delta=f"é–€æª»: {detail['thresh']:.1%}")
                            st.metric("æœ€ä½³åƒæ•¸ (Quantile)", detail['best_q'])
                            
                        with c2:
                            # Draw Chart
                            if detail['curve'] is not None:
                                st.write("**æœ€è¿‘æœŸå›æ¸¬è¡¨ç¾ (Last 20% Samples)**")
                                fig = px.line(detail['curve'], title=f"{t} Equity Curve (Validation)")
                                st.plotly_chart(fig, use_container_width=True)
                                
                        st.caption("æœ€è¿‘ 5 ç­†æ•¸æ“šç‰¹å¾µï¼š")
                        st.dataframe(detail['df_feat_tail'])

                    with tab2:
                        st.markdown(f"**{t} æœ€æ–°ç›¸é—œæ–°è (Google News)**")
                        news_list = get_stock_news(t)
                        if news_list:
                            for n in news_list:
                                title = n['title']
                                # Keyword Highlighting
                                keywords = ['AI', 'Nvidia', 'Memory', 'DRAM', 'Server', 'Chip', 'Semiconductor', 'å°ç©é›»', 'è¼é”', 'è¨˜æ†¶é«”']
                                for k in keywords:
                                    if k.lower() in title.lower():
                                        title = f"ğŸ”¥ {title}"
                                        break
                                
                                st.markdown(f"- [{title}]({n['link']}) \n  <small style='color:gray'>{n['published']}</small>", unsafe_allow_html=True)
                        else:
                            st.info("æš«ç„¡ç›¸é—œæ–°èæˆ–é€£ç·šé€¾æ™‚ã€‚")
else:
    st.info("ğŸ‘ˆ è«‹åœ¨å·¦å´è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿæ¸…å–® (æ”¯æ´å¤šæª”)ï¼ŒæŒ‰ä¸‹ 'é–‹å§‹æ‰¹æ¬¡åˆ†æ' å³å¯ã€‚")
